{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. 参数配置"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-11T09:11:38.898673Z","iopub.status.busy":"2024-06-11T09:11:38.898332Z","iopub.status.idle":"2024-06-11T09:11:47.050015Z","shell.execute_reply":"2024-06-11T09:11:47.049211Z","shell.execute_reply.started":"2024-06-11T09:11:38.898644Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from transformers import BertTokenizer, BertModel, GPT2Tokenizer, GPT2LMHeadModel\n","from torch.distributions import MultivariateNormal, Categorical\n","\n","import matplotlib.pyplot as plt\n","\n","import time\n","\n","import random\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:11:47.052504Z","iopub.status.busy":"2024-06-11T09:11:47.051678Z","iopub.status.idle":"2024-06-11T09:11:49.826684Z","shell.execute_reply":"2024-06-11T09:11:49.825620Z","shell.execute_reply.started":"2024-06-11T09:11:47.052467Z"},"trusted":true},"outputs":[],"source":["## wandb login\n","import wandb\n","# from kaggle_secrets import UserSecretsClient\n","# user_secrets = UserSecretsClient()\n","# secret_value_0 = user_secrets.get_secret(\"wandb_key\")\n","\n","#wandb.login(key ='75d6ae3a989e4630c051b36e121c363339e0b5a5')"]},{"cell_type":"markdown","metadata":{},"source":["|Dateset|0%|25%|50%|75%|\n","|---|---|---|---|---|\n","|Banking|0+77|19+58|39+38|58+19|\n","|Clinc150|0+150|38+112|75+75|113+37|\n","|StackOverflow|0+20|5+15|10+10|15+5|"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:11:49.828622Z","iopub.status.busy":"2024-06-11T09:11:49.827946Z","iopub.status.idle":"2024-06-11T09:11:49.833929Z","shell.execute_reply":"2024-06-11T09:11:49.833010Z","shell.execute_reply.started":"2024-06-11T09:11:49.828590Z"},"trusted":true},"outputs":[],"source":["## Config\n","class config:\n","    seed = 200\n","    \n","    ## train parameters\n","    BATCH_SIZE = 25\n","    EPOCHES = 100\n","    num_warmup_rate=0.05\n","#     n_clusters = 140\n","    model_name = 'VAE_semi'\n","    dataset_name = 'clinc' # clinc / stackoverflow\n","    n = 75"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["random.seed(config.seed)"]},{"cell_type":"markdown","metadata":{},"source":["# 2. 数据准备"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:11:49.837246Z","iopub.status.busy":"2024-06-11T09:11:49.836848Z","iopub.status.idle":"2024-06-11T09:11:49.916095Z","shell.execute_reply":"2024-06-11T09:11:49.915143Z","shell.execute_reply.started":"2024-06-11T09:11:49.837216Z"},"trusted":true},"outputs":[],"source":["## Load data\n","\n","df = pd.read_csv('/home/zhaojinyue/workspace/intent-cluster/archive/data/clinc/train.tsv', sep='\\t')\n","\n","df_te = pd.read_csv('/home/zhaojinyue/workspace/intent-cluster/archive/data/clinc/test.tsv', sep='\\t')\n","\n","# df_dev = pd.read_csv(f'/kaggle/input/intent-dataset/data/{dataset_name}/dev.tsv', sep='\\t')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:11:49.917439Z","iopub.status.busy":"2024-06-11T09:11:49.917156Z","iopub.status.idle":"2024-06-11T09:11:49.929114Z","shell.execute_reply":"2024-06-11T09:11:49.928002Z","shell.execute_reply.started":"2024-06-11T09:11:49.917416Z"},"trusted":true},"outputs":[],"source":["num_classes = df['label'].nunique()#*2"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:11:49.931001Z","iopub.status.busy":"2024-06-11T09:11:49.930668Z","iopub.status.idle":"2024-06-11T09:11:49.947105Z","shell.execute_reply":"2024-06-11T09:11:49.946350Z","shell.execute_reply.started":"2024-06-11T09:11:49.930950Z"},"trusted":true},"outputs":[],"source":["label_mapping = {v:i for i,v in enumerate(df['label'].unique())}\n","df['label_num'] = df['label'].map(label_mapping)\n","df_te['label_num'] = df_te['label'].map(label_mapping)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:11:49.948550Z","iopub.status.busy":"2024-06-11T09:11:49.948224Z","iopub.status.idle":"2024-06-11T09:11:50.627728Z","shell.execute_reply":"2024-06-11T09:11:50.626764Z","shell.execute_reply.started":"2024-06-11T09:11:49.948523Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('/home/zhaojinyue/workspace/intent-cluster/bert')\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, num_classes=20):\n","        self.data = dataframe\n","        self.num_classes = num_classes\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, index):\n","        text = self.data.loc[index, 'text']\n","        encoded_input = tokenizer(text, return_tensors='pt', add_special_tokens=True, max_length=128, padding='max_length')\n","        label = self.data.loc[index, 'label_num']\n","        one_hot_label = F.one_hot(torch.tensor(label), num_classes=self.num_classes)\n","        inputs_ids = encoded_input['input_ids'].squeeze(0)\n","        attention_mask = encoded_input['attention_mask'].squeeze(0)\n","        return inputs_ids, attention_mask, one_hot_label"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:11:50.629186Z","iopub.status.busy":"2024-06-11T09:11:50.628883Z","iopub.status.idle":"2024-06-11T09:11:50.641216Z","shell.execute_reply":"2024-06-11T09:11:50.640222Z","shell.execute_reply.started":"2024-06-11T09:11:50.629161Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['make_call', 'what_are_your_hobbies', 'cook_time', 'tire_change', 'pay_bill', 'calendar_update', 'change_language', 'goodbye', 'no', 'fun_fact', 'lost_luggage', 'change_ai_name', 'cancel', 'bill_balance', 'travel_suggestion', 'maybe', 'reminder', 'how_busy', 'smart_home', 'book_flight', 'spending_history', 'what_can_i_ask_you', 'do_you_have_pets', 'mpg', 'taxes', 'thank_you', 'definition', 'pin_change', 'text', 'who_do_you_work_for', 'measurement_conversion', 'order_status', 'new_card', 'payday', 'oil_change_how', 'redeem_rewards', 'rewards_balance', 'damaged_card', 'timezone', 'order_checks', 'ingredient_substitution', 'traffic', 'international_fees', 'schedule_maintenance', 'todo_list', 'balance', 'carry_on', 'next_song', 'how_old_are_you', 'flight_status', 'pto_used', 'jump_start', 'directions', 'tell_joke', 'restaurant_reviews', 'travel_alert', 'international_visa', 'gas', 'meeting_schedule', 'transactions', 'shopping_list_update', 'change_volume', 'transfer', 'next_holiday', 'order', 'apr', 'calories', 'todo_list_update', 'nutrition_info', 'ingredients_list', 'play_music', 'travel_notification', 'credit_limit_change', 'distance', 'are_you_a_bot']\n"]}],"source":["labeled_intents = random.sample(list(label_mapping.keys()), config.n)\n","print(labeled_intents)\n","labeled_idx = df['label'].isin(labeled_intents)\n","df_labeled = df[labeled_idx]\n","df_unlabeled = df[~labeled_idx]\n","\n","df_labeled.reset_index(drop=True, inplace=True)\n","df_unlabeled.reset_index(drop=True, inplace=True)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:11:50.643555Z","iopub.status.busy":"2024-06-11T09:11:50.642517Z","iopub.status.idle":"2024-06-11T09:11:50.648908Z","shell.execute_reply":"2024-06-11T09:11:50.648000Z","shell.execute_reply.started":"2024-06-11T09:11:50.643519Z"},"trusted":true},"outputs":[],"source":["# dataset = CustomDataset(df, num_classes)\n","# val_dataset = CustomDataset(df_te, num_classes)\n","labeled_dataset = CustomDataset(df_labeled, num_classes)\n","contrast_dataset = CustomDataset(df_unlabeled, num_classes)\n","val_dataset = CustomDataset(df_te, num_classes)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:33:02.871419Z","iopub.status.busy":"2024-06-11T09:33:02.871031Z","iopub.status.idle":"2024-06-11T09:33:02.878866Z","shell.execute_reply":"2024-06-11T09:33:02.877778Z","shell.execute_reply.started":"2024-06-11T09:33:02.871393Z"},"trusted":true},"outputs":[],"source":["batch_size = config.BATCH_SIZE  # 批量大小\n","shuffle = True  # 打乱数据\n","labeled_dataloader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n","contrast_dataloader = DataLoader(contrast_dataset, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size*2)"]},{"cell_type":"markdown","metadata":{},"source":["# 3.模型定义"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:11:50.661202Z","iopub.status.busy":"2024-06-11T09:11:50.660731Z","iopub.status.idle":"2024-06-11T09:12:06.542922Z","shell.execute_reply":"2024-06-11T09:12:06.542005Z","shell.execute_reply.started":"2024-06-11T09:11:50.661142Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at /home/zhaojinyue/workspace/intent-cluster/bert were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at /home/zhaojinyue/workspace/intent-cluster/bert were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["VAE_DEC(\n","  (bert_encoder): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (fc_mu): Linear(in_features=768, out_features=768, bias=True)\n","  (bn_mu): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (fc1): Linear(in_features=768, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=150, bias=True)\n","  (relu): ReLU()\n","  (softmax): Softmax(dim=1)\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# 加载BERT和GPT-2\n","bert_tokenizer = BertTokenizer.from_pretrained('/home/zhaojinyue/workspace/intent-cluster/bert')\n","bert_model = BertModel.from_pretrained('/home/zhaojinyue/workspace/intent-cluster/bert')\n","\n","class VAE_DEC(nn.Module):\n","    def __init__(self, bert_model, num_classes):\n","        super(VAE_DEC, self).__init__()\n","        self.bert_encoder = bert_model\n","        self.latent_dim = bert_model.config.hidden_size\n","        \n","        self.fc_mu = nn.Linear(self.latent_dim, self.latent_dim)\n","        self.bn_mu = nn.BatchNorm1d(self.latent_dim)  # 添加批量归一化层\n","        \n","        self.dropout = nn.Dropout(0.1)\n","        self.fc1 = nn.Linear(self.latent_dim, 256)\n","        self.fc2 = nn.Linear(256, num_classes)\n","        self.relu = nn.ReLU()\n","        self.softmax = nn.Softmax(dim=1)        \n","        \n","    def encode(self, input_ids, attention_mask=None):\n","        outputs = self.bert_encoder(input_ids, attention_mask=attention_mask)\n","        hidden_state = outputs.last_hidden_state[:, 0, :]  # 使用[CLS] token表示\n","        mu = self.bn_mu(self.fc_mu(hidden_state))\n","        return mu\n","        \n","    def forward(self, input_ids, attention_mask):\n","        mu = self.encode(input_ids, attention_mask)\n","        hidden = self.relu(self.fc1(mu))\n","        logits = self.softmax(self.fc2(hidden))\n","        logits = self.dropout(logits)\n","        return mu, logits\n","\n","bert_model = BertModel.from_pretrained('/home/zhaojinyue/workspace/intent-cluster/bert')\n","\n","model = VAE_DEC(bert_model, num_classes = num_classes )\n","\n","model_dict = model.state_dict()\n","\n","pretrained_dict = torch.load('/home/zhaojinyue/workspace/intent-cluster/NEW/vae_pretrain_clinc150_model_best_tr.pth',map_location=torch.device('cpu'))\n","\n","pretrained_dict = {key: value for key, value in pretrained_dict.items() if key in model_dict }\n","model_dict.update(pretrained_dict)\n","model.load_state_dict(model_dict)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["# 3.损失函数和优化器"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:12:06.544548Z","iopub.status.busy":"2024-06-11T09:12:06.544189Z","iopub.status.idle":"2024-06-11T09:12:23.756224Z","shell.execute_reply":"2024-06-11T09:12:23.755286Z","shell.execute_reply.started":"2024-06-11T09:12:06.544518Z"},"trusted":true},"outputs":[],"source":["## wandb.init()\n","def class2dict(f):\n","    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","# wandb.init(project='NLP-intent-VAE-supuervised', \n","#     name=f'{config.dataset_name}_n{config.n}_seed{config.seed}_pretrain',\n","#     config=class2dict(config),\n","#     group=config.model_name,\n","#     job_type=\"train\",\n","#     anonymous=\"must\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:12:23.758251Z","iopub.status.busy":"2024-06-11T09:12:23.757706Z","iopub.status.idle":"2024-06-11T09:12:23.778194Z","shell.execute_reply":"2024-06-11T09:12:23.777033Z","shell.execute_reply.started":"2024-06-11T09:12:23.758218Z"},"trusted":true},"outputs":[],"source":["## SupConLoss 有监督的对比学习Loss\n","class SupConLoss(nn.Module):\n","    \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n","    It also supports the unsupervised contrastive loss in SimCLR\"\"\"\n","    def __init__(self, contrast_mode='all'):\n","        super(SupConLoss, self).__init__()\n","        self.contrast_mode = contrast_mode\n","\n","    def forward(self, features, labels=None, mask=None, temperature = 0.07, device = None):\n","        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n","        it degenerates to SimCLR unsupervised loss:\n","        https://arxiv.org/pdf/2002.05709.pdf\n","        Args:\n","            features: hidden vector of shape [bsz, n_views, ...].\n","            labels: ground truth of shape [bsz].\n","            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n","                has the same class as sample i. Can be asymmetric.\n","        Returns:\n","            A loss scalar.\n","        \"\"\"\n","\n","        if len(features.shape) < 3:\n","            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n","                             'at least 3 dimensions are required')\n","        if len(features.shape) > 3:\n","            features = features.view(features.shape[0], features.shape[1], -1)\n","\n","        batch_size = features.shape[0]\n","        if labels is not None and mask is not None:\n","            raise ValueError('Cannot define both `labels` and `mask`')\n","        elif labels is None and mask is None:\n","            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n","        elif labels is not None:\n","            labels = labels.contiguous().view(-1, 1)\n","            if labels.shape[0] != batch_size:\n","                raise ValueError('Num of labels does not match num of features')\n","            mask = torch.eq(labels, labels.T).float().to(device)\n","        else:\n","            mask = mask.float().to(device)\n","\n","        contrast_count = features.shape[1]\n","        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n","        if self.contrast_mode == 'one':\n","            anchor_feature = features[:, 0]\n","            anchor_count = 1\n","        elif self.contrast_mode == 'all':\n","            anchor_feature = contrast_feature\n","            anchor_count = contrast_count\n","        else:\n","            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n","\n","        # compute logits\n","        anchor_dot_contrast = torch.div(\n","            torch.matmul(anchor_feature, contrast_feature.T),\n","            temperature)\n","        # for numerical stability\n","        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n","        logits = anchor_dot_contrast - logits_max.detach()\n","\n","        # tile mask\n","        mask = mask.repeat(anchor_count, contrast_count)\n","        # mask-out self-contrast cases\n","        logits_mask = torch.scatter(\n","            torch.ones_like(mask),\n","            1,\n","            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n","            0\n","        )\n","        mask = mask * logits_mask\n","\n","        # compute log_prob\n","        exp_logits = torch.exp(logits) * logits_mask\n","        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n","\n","        # compute mean of log-likelihood over positive\n","        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n","\n","        # loss\n","        loss = - mean_log_prob_pos\n","        loss = loss.view(anchor_count, batch_size).mean()\n","\n","        return loss"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:12:23.780369Z","iopub.status.busy":"2024-06-11T09:12:23.780028Z","iopub.status.idle":"2024-06-11T09:12:23.798945Z","shell.execute_reply":"2024-06-11T09:12:23.798095Z","shell.execute_reply.started":"2024-06-11T09:12:23.780337Z"},"trusted":true},"outputs":[],"source":["## Loss\n","each_epoch_steps = len(labeled_dataloader)\n","epoches = config.EPOCHES\n","\n","criterion = nn.CrossEntropyLoss()\n","contrast_criterion = SupConLoss()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:12:23.800784Z","iopub.status.busy":"2024-06-11T09:12:23.800447Z","iopub.status.idle":"2024-06-11T09:12:23.823910Z","shell.execute_reply":"2024-06-11T09:12:23.822738Z","shell.execute_reply.started":"2024-06-11T09:12:23.800753Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-30 09:13:43.551119: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["## Optimizer\n","optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=1e-6)\n","\n","## Scheduler\n","from transformers import get_cosine_schedule_with_warmup\n","num_train_steps = config.EPOCHES*each_epoch_steps\n","num_warmup_steps = int(num_train_steps*config.num_warmup_rate)\n","scheduler = get_cosine_schedule_with_warmup(\n","    optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps, num_cycles=0.5)"]},{"cell_type":"markdown","metadata":{},"source":["# 4.训练模型"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:12:23.825742Z","iopub.status.busy":"2024-06-11T09:12:23.825403Z","iopub.status.idle":"2024-06-11T09:12:24.846701Z","shell.execute_reply":"2024-06-11T09:12:24.845221Z","shell.execute_reply.started":"2024-06-11T09:12:23.825704Z"},"trusted":true},"outputs":[],"source":["from sklearn.cluster import KMeans\n","from tqdm.notebook import tqdm\n","\n","feat_dim = 768"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:12:24.848502Z","iopub.status.busy":"2024-06-11T09:12:24.848156Z","iopub.status.idle":"2024-06-11T09:12:24.861844Z","shell.execute_reply":"2024-06-11T09:12:24.860806Z","shell.execute_reply.started":"2024-06-11T09:12:24.848472Z"},"trusted":true},"outputs":[],"source":["## evalute\n","from sklearn.metrics.cluster import normalized_mutual_info_score\n","from sklearn.metrics import adjusted_rand_score\n","# from sklearn.metrics import accuracy_score\n","\n","from scipy.optimize import linear_sum_assignment\n","\n","def calculate_acc(true_labels, pred_labels):\n","    true_labels = np.array(true_labels, dtype=int)\n","    pred_labels = np.array(pred_labels, dtype=int)\n","    # 构建混淆矩阵\n","    max_label = max(max(true_labels), max(pred_labels)) + 1\n","    confusion_matrix = np.zeros((max_label, max_label), dtype=int)\n","    \n","    for t, p in zip(true_labels, pred_labels):\n","        confusion_matrix[t, p] += 1\n","    \n","    # 使用匈牙利算法找到最佳匹配\n","    row_ind, col_ind = linear_sum_assignment(-confusion_matrix)\n","    \n","    # 计算准确率\n","    accuracy = confusion_matrix[row_ind, col_ind].sum() / len(true_labels)\n","    return accuracy\n","\n","def evalute(true_labels, cluster_labels):\n","    # 计算归一化互信息\n","    nmi = normalized_mutual_info_score(true_labels, cluster_labels, average_method='arithmetic')\n","    # 计算调整兰德系数\n","    ari = adjusted_rand_score(true_labels, cluster_labels)\n","    # 计算聚类准确率\n","    acc = calculate_acc(true_labels, cluster_labels)\n","\n","    return nmi, ari, acc\n","\n","# nmi, ari, acc = evalute(true_labels, cluster_labels)\n","\n","# https://arxiv.org/pdf/2304.07699\n","# ===========================\n","# | NMI    | ARI    | ACC   |\n","# | 87.41  | 69.54  | 78.36 |"]},{"cell_type":"markdown","metadata":{},"source":["# semi-supervised"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:12:24.863943Z","iopub.status.busy":"2024-06-11T09:12:24.863568Z","iopub.status.idle":"2024-06-11T09:12:24.875069Z","shell.execute_reply":"2024-06-11T09:12:24.874152Z","shell.execute_reply.started":"2024-06-11T09:12:24.863908Z"},"trusted":true},"outputs":[],"source":["from itertools import cycle"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:34:05.398234Z","iopub.status.busy":"2024-06-11T09:34:05.397840Z","iopub.status.idle":"2024-06-11T09:43:38.145532Z","shell.execute_reply":"2024-06-11T09:43:38.143908Z","shell.execute_reply.started":"2024-06-11T09:34:05.398207Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[Epoch 1/100] Train Loss: 6.96, Test Loss: 5.01, Test acc: 0.01, Test evaluate: 0.35944246333598484, 0.01847347449506412, 0.10533333333333333, lr: 4.000000000000001e-06, time: 221s\n","[Epoch 2/100] Train Loss: 6.74, Test Loss: 5.01, Test acc: 0.07, Test evaluate: 0.4289370195670496, 0.03874254080818828, 0.11733333333333333, lr: 8.000000000000001e-06, time: 223s\n","[Epoch 3/100] Train Loss: 6.53, Test Loss: 4.98, Test acc: 0.08, Test evaluate: 0.4588037802198231, 0.03772565407542373, 0.09733333333333333, lr: 1.2e-05, time: 223s\n","[Epoch 4/100] Train Loss: 6.37, Test Loss: 4.89, Test acc: 0.17, Test evaluate: 0.5797288461043686, 0.09690893138369139, 0.18133333333333335, lr: 1.6000000000000003e-05, time: 223s\n","[Epoch 5/100] Train Loss: 6.15, Test Loss: 4.82, Test acc: 0.22, Test evaluate: 0.6358904776111624, 0.15428997298888492, 0.22355555555555556, lr: 2e-05, time: 223s\n","[Epoch 6/100] Train Loss: 5.97, Test Loss: 4.73, Test acc: 0.32, Test evaluate: 0.7069630124859875, 0.2366776275777848, 0.32266666666666666, lr: 1.999453257340926e-05, time: 223s\n","[Epoch 7/100] Train Loss: 5.77, Test Loss: 4.67, Test acc: 0.37, Test evaluate: 0.7286523250512262, 0.265882123254793, 0.3728888888888889, lr: 1.9978136272187745e-05, time: 223s\n","[Epoch 8/100] Train Loss: 5.64, Test Loss: 4.63, Test acc: 0.41, Test evaluate: 0.7556498728771317, 0.31577926149099345, 0.4106666666666667, lr: 1.9950829025450116e-05, time: 223s\n","[Epoch 9/100] Train Loss: 5.55, Test Loss: 4.58, Test acc: 0.45, Test evaluate: 0.778534199402128, 0.3568135707511203, 0.4537777777777778, lr: 1.9912640693269754e-05, time: 223s\n","[Epoch 10/100] Train Loss: 5.45, Test Loss: 4.55, Test acc: 0.47, Test evaluate: 0.787204323749469, 0.38179183774321307, 0.4751111111111111, lr: 1.9863613034027224e-05, time: 223s\n","[Epoch 11/100] Train Loss: 5.41, Test Loss: 4.55, Test acc: 0.47, Test evaluate: 0.7911234813941561, 0.38902653431043865, 0.4742222222222222, lr: 1.9803799658748096e-05, time: 223s\n","[Epoch 12/100] Train Loss: 5.39, Test Loss: 4.54, Test acc: 0.48, Test evaluate: 0.794505229014824, 0.39738917798159185, 0.48133333333333334, lr: 1.973326597248006e-05, time: 224s\n","[Epoch 13/100] Train Loss: 5.37, Test Loss: 4.54, Test acc: 0.48, Test evaluate: 0.7976142283644155, 0.40034714301777896, 0.4831111111111111, lr: 1.9652089102773487e-05, time: 223s\n","[Epoch 14/100] Train Loss: 5.36, Test Loss: 4.54, Test acc: 0.48, Test evaluate: 0.7974843493592854, 0.39937544376710826, 0.4826666666666667, lr: 1.9560357815343577e-05, time: 223s\n","[Epoch 15/100] Train Loss: 5.36, Test Loss: 4.54, Test acc: 0.48, Test evaluate: 0.7975215282458087, 0.40213557817004214, 0.4826666666666667, lr: 1.9458172417006347e-05, time: 223s\n","[Epoch 16/100] Train Loss: 5.36, Test Loss: 4.54, Test acc: 0.48, Test evaluate: 0.7987999733368194, 0.40441206091811743, 0.48355555555555557, lr: 1.934564464599461e-05, time: 223s\n","[Epoch 17/100] Train Loss: 5.37, Test Loss: 4.54, Test acc: 0.48, Test evaluate: 0.7955447972561608, 0.4007208564015579, 0.48355555555555557, lr: 1.922289754977385e-05, time: 223s\n","[Epoch 18/100] Train Loss: 5.36, Test Loss: 4.54, Test acc: 0.48, Test evaluate: 0.7972301313585103, 0.4014741288295986, 0.48577777777777775, lr: 1.909006535049163e-05, time: 223s\n","[Epoch 19/100] Train Loss: 5.35, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.8015060268280125, 0.40815613689823826, 0.492, lr: 1.8947293298207637e-05, time: 223s\n","[Epoch 20/100] Train Loss: 5.35, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7984847146757257, 0.404470108073442, 0.49066666666666664, lr: 1.879473751206489e-05, time: 223s\n","[Epoch 21/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7982716291233152, 0.40361223339641156, 0.4902222222222222, lr: 1.863256480957574e-05, time: 223s\n","[Epoch 22/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7990999532952873, 0.4060493296697454, 0.48977777777777776, lr: 1.8460952524209355e-05, time: 223s\n","[Epoch 23/100] Train Loss: 5.35, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7985957774388919, 0.41153165395328506, 0.4911111111111111, lr: 1.8280088311480203e-05, time: 223s\n","[Epoch 24/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7995795948387329, 0.40490372271324504, 0.49066666666666664, lr: 1.8090169943749477e-05, time: 223s\n","[Epoch 25/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.8012694321800666, 0.40817814812707887, 0.4902222222222222, lr: 1.789140509396394e-05, time: 223s\n","[Epoch 26/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.8009072661714142, 0.41181437057532877, 0.4915555555555556, lr: 1.7684011108568593e-05, time: 223s\n","[Epoch 27/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7998518312668884, 0.4065627060130406, 0.4915555555555556, lr: 1.7468214769841542e-05, time: 223s\n","[Epoch 28/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7879074145988192, 0.3851600871753657, 0.4888888888888889, lr: 1.7244252047910893e-05, time: 223s\n","[Epoch 29/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7994995276276943, 0.40620801510989885, 0.4911111111111111, lr: 1.7012367842724887e-05, time: 223s\n","[Epoch 30/100] Train Loss: 5.32, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7972602437377422, 0.40716643310706646, 0.4915555555555556, lr: 1.6772815716257414e-05, time: 223s\n","[Epoch 31/100] Train Loss: 5.35, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7969905053994687, 0.4039529305728545, 0.49066666666666664, lr: 1.6525857615241686e-05, time: 223s\n","[Epoch 32/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7938834524306617, 0.3995717352748324, 0.48977777777777776, lr: 1.6271763584735373e-05, time: 223s\n","[Epoch 33/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7961596084392563, 0.4043888673958169, 0.48844444444444446, lr: 1.6010811472830253e-05, time: 223s\n","[Epoch 34/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7987529937163028, 0.4082464258302002, 0.48933333333333334, lr: 1.5743286626829437e-05, time: 223s\n","[Epoch 35/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.798391403968379, 0.4059307411795177, 0.48933333333333334, lr: 1.5469481581224274e-05, time: 223s\n","[Epoch 36/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.8011964449475187, 0.4116478085182038, 0.4902222222222222, lr: 1.5189695737812153e-05, time: 223s\n","[Epoch 37/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.8008330442301609, 0.4139170092385331, 0.4902222222222222, lr: 1.4904235038305084e-05, time: 223s\n","[Epoch 38/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.798921434579533, 0.4082680533430817, 0.4902222222222222, lr: 1.461341162978688e-05, time: 223s\n","[Epoch 39/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7971180116745625, 0.4063426330248281, 0.4911111111111111, lr: 1.4317543523384928e-05, time: 223s\n","[Epoch 40/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7984892301823069, 0.41079754037671695, 0.4915555555555556, lr: 1.4016954246529697e-05, time: 223s\n","[Epoch 41/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7922678108333496, 0.39834784210105234, 0.48977777777777776, lr: 1.3711972489182208e-05, time: 223s\n","[Epoch 42/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7976286501296538, 0.40869352788622726, 0.49066666666666664, lr: 1.3402931744416432e-05, time: 223s\n","[Epoch 43/100] Train Loss: 5.32, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.8000635063957123, 0.40519911318617113, 0.4902222222222222, lr: 1.3090169943749475e-05, time: 223s\n","[Epoch 44/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7974983106001259, 0.4037298691305777, 0.4888888888888889, lr: 1.2774029087618448e-05, time: 224s\n","[Epoch 45/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7994443341560625, 0.408185152302062, 0.48977777777777776, lr: 1.2454854871407993e-05, time: 224s\n","[Epoch 46/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7939343151803678, 0.4045965107723876, 0.48933333333333334, lr: 1.213299630743747e-05, time: 224s\n","[Epoch 47/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7969331659624291, 0.40812272121950377, 0.4888888888888889, lr: 1.1808805343321102e-05, time: 223s\n","[Epoch 48/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7981050621108307, 0.4118427342994126, 0.4888888888888889, lr: 1.148263647711842e-05, time: 224s\n","[Epoch 49/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.799480990381034, 0.4090977578745781, 0.48977777777777776, lr: 1.1154846369695864e-05, time: 224s\n","[Epoch 50/100] Train Loss: 5.32, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7979786803916441, 0.4052029009240781, 0.48844444444444446, lr: 1.0825793454723325e-05, time: 223s\n","[Epoch 51/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7970414672687015, 0.4050988148484753, 0.48933333333333334, lr: 1.0495837546732224e-05, time: 224s\n","[Epoch 52/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7949796150390599, 0.40408771029319707, 0.48933333333333334, lr: 1.0165339447663586e-05, time: 223s\n","[Epoch 53/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7964360031713937, 0.40292651461080736, 0.4888888888888889, lr: 9.834660552336415e-06, time: 223s\n","[Epoch 54/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7989115982116262, 0.4057668292152723, 0.4902222222222222, lr: 9.504162453267776e-06, time: 224s\n","[Epoch 55/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7999191685997292, 0.4064253947964102, 0.4911111111111111, lr: 9.174206545276678e-06, time: 223s\n","[Epoch 56/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7973617254398759, 0.405937908365009, 0.48977777777777776, lr: 8.84515363030414e-06, time: 223s\n","[Epoch 57/100] Train Loss: 5.32, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.8000818175373094, 0.40744673763952194, 0.4911111111111111, lr: 8.51736352288158e-06, time: 223s\n","[Epoch 58/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.8007013903794477, 0.407609796856814, 0.4902222222222222, lr: 8.191194656678905e-06, time: 223s\n","[Epoch 59/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7988764381763976, 0.40306076274561997, 0.49066666666666664, lr: 7.867003692562533e-06, time: 223s\n","[Epoch 60/100] Train Loss: 5.32, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.801362367712247, 0.40763555963928605, 0.4911111111111111, lr: 7.545145128592009e-06, time: 223s\n","[Epoch 61/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.8004505138310852, 0.40396897740346493, 0.48977777777777776, lr: 7.225970912381557e-06, time: 223s\n","[Epoch 62/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7999321945857927, 0.40580010598013944, 0.49066666666666664, lr: 6.909830056250527e-06, time: 223s\n","[Epoch 63/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7978430938103398, 0.40291030177059156, 0.48977777777777776, lr: 6.59706825558357e-06, time: 223s\n","[Epoch 64/100] Train Loss: 5.32, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7979111428311441, 0.40323989029772045, 0.4902222222222222, lr: 6.2880275108177915e-06, time: 223s\n","[Epoch 65/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7976851449534936, 0.40509049878894254, 0.4902222222222222, lr: 5.983045753470308e-06, time: 223s\n","[Epoch 66/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.795207769643441, 0.40324337599141463, 0.48933333333333334, lr: 5.6824564766150724e-06, time: 223s\n","[Epoch 67/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7976486117751441, 0.40991234224027007, 0.4902222222222222, lr: 5.386588370213124e-06, time: 223s\n","[Epoch 68/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7992727912635758, 0.4109552121090797, 0.49066666666666664, lr: 5.095764961694923e-06, time: 223s\n","[Epoch 69/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7982868834100253, 0.40619313416004377, 0.4902222222222222, lr: 4.8103042621878515e-06, time: 223s\n","[Epoch 70/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.799594693741445, 0.4078934579542319, 0.48977777777777776, lr: 4.530518418775734e-06, time: 223s\n","[Epoch 71/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7998096209799441, 0.40858531568808953, 0.48977777777777776, lr: 4.256713373170565e-06, time: 223s\n","[Epoch 72/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7964816518951214, 0.4064166647915872, 0.48933333333333334, lr: 3.989188527169749e-06, time: 223s\n","[Epoch 73/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7962571709281084, 0.4043473247484752, 0.48977777777777776, lr: 3.72823641526463e-06, time: 223s\n","[Epoch 74/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7987707223498651, 0.4074958921798345, 0.49066666666666664, lr: 3.4741423847583134e-06, time: 223s\n","[Epoch 75/100] Train Loss: 5.34, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7970967774784933, 0.4043244965321472, 0.48977777777777776, lr: 3.2271842837425917e-06, time: 223s\n","[Epoch 76/100] Train Loss: 5.32, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7978655187154393, 0.40686535051172323, 0.49066666666666664, lr: 2.9876321572751143e-06, time: 223s\n","[Epoch 77/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7987619027589961, 0.40589118207244396, 0.4902222222222222, lr: 2.7557479520891104e-06, time: 223s\n","[Epoch 78/100] Train Loss: 5.32, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.8005451176699457, 0.40990974725808316, 0.4911111111111111, lr: 2.5317852301584642e-06, time: 223s\n","[Epoch 79/100] Train Loss: 5.33, Test Loss: 4.53, Test acc: 0.49, Test evaluate: 0.7990015840988711, 0.4074690394949845, 0.49066666666666664, lr: 2.315988891431412e-06, time: 223s\n"]}],"source":["## Traing\n","best_loss = 1_000\n","\n","for epoch in range(epoches):\n","    ## train\n","    model.train()\n","    st = time.time()\n","    losses = []\n","\n","    for step, (batch_labeled, batch_unlabeled) in enumerate(zip(cycle(labeled_dataloader), contrast_dataloader)):\n","        input_ids_labeled, attention_mask_labeled, labels = batch_labeled\n","        input_ids_labeled, attention_mask_labeled, labels = input_ids_labeled.to(device, dtype=torch.long), attention_mask_labeled.to(device, dtype=torch.long), labels.to(device, dtype=torch.float)\n","\n","        input_ids_unlabeled, attention_mask_unlabeled, unlabels = batch_unlabeled\n","        input_ids_unlabeled, attention_mask_unlabeled = input_ids_labeled.to(device, dtype=torch.long), attention_mask_labeled.to(device, dtype=torch.long)\n","\n","        unlabels_ = unlabels.argmax(dim=1)\n","        unlabels_ids = torch.full_like(unlabels_,-1)\n","        unlabels_ids = unlabels_ids.to(device)\n","        labels_ids = labels.argmax(dim=1)\n","\n","        input_ids = torch.cat((input_ids_labeled, input_ids_unlabeled))\n","        attention_mask = torch.cat((attention_mask_labeled, attention_mask_unlabeled))\n","        label_ids = torch.cat((labels_ids, unlabels_ids))\n","\n","        batch_size = input_ids.shape[0]\n","        labels_expand = label_ids.expand(batch_size, batch_size)\n","        mask = torch.eq(labels_expand, labels_expand.T).long()\n","        mask[label_ids == -1, :] = 0\n","\n","        logits_mask = torch.scatter(\n","            mask,\n","            0,\n","            torch.arange(batch_size).unsqueeze(0).to(device),\n","            1\n","        )\n","\n","        ## 标注数据 labeled data\n","        z, logits = model(input_ids_labeled, attention_mask_labeled)\n","        loss_ce = criterion(logits, labels)\n","        ## 非标注数据 unlabeled data 对比学习\n","        # 正样本对；负样本对 最终会体现在损失函数里边\n","        z_a,logits_a = model(input_ids, attention_mask)\n","        z_b,logits_b = model(input_ids, attention_mask)\n","\n","        norm_z_a = F.normalize(z_a)\n","        norm_z_b = F.normalize(z_b)\n","\n","        contrastive_zs = torch.cat((norm_z_a.unsqueeze(1), norm_z_b.unsqueeze(1)), dim = 1)\n","\n","        loss_contrast = contrast_criterion(contrastive_zs, mask = logits_mask, temperature = 0.07, device = device)\n","        loss = loss_contrast + loss_ce\n","\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()        \n","        losses.append(loss.item())\n","        scheduler.step()\n","        # 更新学习率\n","    \n","    v_losses = []\n","    v_accs = []\n","    ## validation\n","    model.eval()\n","    prs=[]\n","    gts=[]\n","    for input_ids, attention_mask, labels in val_dataloader:\n","        input_ids, attention_mask, labels = input_ids.to(device, dtype=torch.long), attention_mask.to(device, dtype=torch.long), labels.to(device, dtype=torch.float)\n","        with torch.no_grad():\n","            z,logits = model(input_ids, attention_mask)\n","            loss = criterion(logits, labels)\n","            v_losses.append(loss.item())\n","            pr = [p.argmax().cpu().numpy() for p in logits]\n","            gt = [l.argmax().cpu().numpy() for l in labels]\n","            prs.extend(pr)\n","            gts.extend(gt)\n","            acc_tmp = [p==g for p,g in zip(pr,gt)]\n","            v_accs.append(sum(acc_tmp)/len(acc_tmp))\n","    ed = time.time()\n","    lr_cur = optimizer.param_groups[0]['lr']\n","    nmi, ari, acc = evalute(gts, prs)\n","    print(f'[Epoch {epoch+1}/{epoches}] Train Loss: {np.mean(losses):.2f}, Test Loss: {np.mean(v_losses):.2f}, Test acc: {np.mean(v_accs):.2f}, Test evaluate: {nmi}, {ari}, {acc}, lr: {lr_cur}, time: {ed-st:.0f}s')\n","    # wandb\n","    # wandb.log({\n","    #     f\"Epoch\": epoch+1,\n","    #     f\"avg_train_loss\": np.mean(losses),\n","    #     f\"avg_test_loss\": np.mean(v_losses),\n","    #     f\"avg_test_acc\": np.mean(v_accs),\n","    #     f\"nmi\": nmi,\n","    #     f\"ari\": ari,\n","    #     f\"acc\": acc,\n","    #     f\"lr\": lr_cur\n","    # })\n","    if best_loss > np.mean(losses):\n","        best_loss = np.mean(losses)\n","        model_path = '/home/zhaojinyue/workspace/intent-cluster/NEW/model_best_tr.pth'\n","        torch.save(model.state_dict(), model_path)\n","        \n","    if epoch % 10==0:\n","        model_ep_path = f'/home/zhaojinyue/workspace/intent-cluster/N75/s200model_epoch{epoch}.pth'\n","        torch.save(model.state_dict(), model_ep_path)"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4969762,"sourceId":8361984,"sourceType":"datasetVersion"},{"datasetId":4996986,"sourceId":8398970,"sourceType":"datasetVersion"},{"datasetId":5108124,"isSourceIdPinned":false,"sourceId":8557534,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
